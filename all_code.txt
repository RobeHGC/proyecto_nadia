# ==== ./userbot.py ====

# userbot.py
"""Punto de entrada principal del bot de Telegram."""
import asyncio
import json
import logging
from datetime import datetime

import redis.asyncio as redis
from telethon import TelegramClient, events

from agents.supervisor_agent import SupervisorAgent
from cognition.cognitive_controller import CognitiveController
from llms.openai_client import OpenAIClient
from memory.user_memory import UserMemoryManager
from utils.config import Config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UserBot:
    """Cliente principal de Telegram que maneja eventos de mensajes."""

    def __init__(self, config: Config):
        """Inicializa el bot con la configuración dada."""
        self.config = config
        self.client = TelegramClient(
            'bot_session',
            config.api_id,
            config.api_hash
        )

        # Inicializar componentes
        self.memory = UserMemoryManager(config.redis_url)
        self.llm = OpenAIClient(config.openai_api_key, config.openai_model)
        self.supervisor = SupervisorAgent(self.llm, self.memory)
        self.cognitive_controller = CognitiveController()

        # Redis para WAL
        self.redis_url = config.redis_url
        self._redis = None

        # Cola de mensajes WAL
        self.message_queue_key = "nadia_message_queue"
        self.processing_key = "nadia_processing"

    async def _get_redis(self):
        """Obtiene o crea la conexión a Redis."""
        if not self._redis:
            self._redis = await redis.from_url(self.redis_url)
        return self._redis

    async def start(self):
        """Inicia la conexión con Telegram y configura handlers."""
        await self.client.start(phone=self.config.phone_number)
        logger.info("Bot iniciado correctamente")

        # Iniciar procesador de cola WAL
        asyncio.create_task(self._process_wal_queue())

        # Registrar handler para mensajes privados
        @self.client.on(events.NewMessage(incoming=True, func=lambda e: e.is_private))
        async def handle_message(event):
            await self._enqueue_message(event)

        # Mantener el bot corriendo
        await self.client.run_until_disconnected()

    async def cleanup(self):
        """Limpia recursos antes de cerrar."""
        try:
            # Cerrar conexión Redis
            if self._redis:
                await self._redis.aclose()

            # Cerrar memoria
            await self.memory.close()

            logger.info("Recursos liberados correctamente")
        except Exception as e:
            logger.error(f"Error durante limpieza: {e}")

    async def _enqueue_message(self, event):
        """Encola un mensaje en el WAL para procesamiento robusto."""
        try:
            r = await self._get_redis()

            # Preparar datos del mensaje
            message_data = {
                'user_id': str(event.sender_id),
                'message': event.text,
                'chat_id': event.chat_id,
                'message_id': event.message.id,
                'timestamp': datetime.now().isoformat()
            }

            # Añadir a la cola WAL
            await r.lpush(self.message_queue_key, json.dumps(message_data))
            logger.info(f"Mensaje encolado en WAL de usuario {message_data['user_id']}")

        except Exception as e:
            logger.error(f"Error encolando mensaje en WAL: {e}")
            # En caso de fallo crítico, procesar directamente
            await self._handle_message_direct(event)

    async def _process_wal_queue(self):
        """Procesa mensajes de la cola WAL de forma continua."""
        logger.info("Iniciando procesador de cola WAL")
        r = await self._get_redis()

        while True:
            try:
                # Bloquear esperando mensajes (timeout de 1 segundo)
                result = await r.brpop(self.message_queue_key, timeout=1)

                if result:
                    _, message_json = result
                    message_data = json.loads(message_json)

                    # Marcar como en procesamiento
                    await r.set(
                        f"{self.processing_key}:{message_data['user_id']}",
                        message_json,
                        ex=300  # Expira en 5 minutos
                    )

                    # Procesar mensaje
                    await self._process_message(message_data)

                    # Limpiar marca de procesamiento
                    await r.delete(f"{self.processing_key}:{message_data['user_id']}")

            except Exception as e:
                logger.error(f"Error en procesador WAL: {e}")
                await asyncio.sleep(1)

    async def _process_message(self, message_data: dict):
        """Procesa un mensaje desde el WAL."""
        try:
            user_id = message_data['user_id']
            message = message_data['message']
            chat_id = message_data['chat_id']

            logger.info(f"Procesando mensaje WAL de {user_id}: {message}")

            # Decidir ruta con el Controlador Cognitivo
            route = self.cognitive_controller.route_message(message)

            if route == 'fast_path':
                # Procesar comando rápido
                response = await self._handle_fast_path(message)
            else:
                # Procesar con el supervisor (vía lenta)
                response = await self.supervisor.process_message(user_id, message)

            # Enviar respuesta
            await self.client.send_message(chat_id, response)
            logger.info(f"Respuesta enviada por ruta {route}: {response[:50]}...")

        except Exception as e:
            logger.error(f"Error procesando mensaje del WAL: {e}")
            # Enviar mensaje de contingencia mejorado
            try:
                await self.client.send_message(
                    message_data['chat_id'],
                    "Uf, perdona si tardo un poco... de repente siento que todo el mundo "
                    "me está hablando a la vez y mi cabeza va a mil. Dame un segundito "
                    "para poner mis ideas en orden. 😅"
                )
            except Exception as send_error:
                logger.error(f"No se pudo enviar mensaje de contingencia: {send_error}")

    async def _handle_fast_path(self, message: str) -> str:
        """Maneja comandos de vía rápida."""
        message_lower = message.lower().strip()

        # Respuestas predefinidas para comandos
        fast_responses = {
            '/ayuda': (
                "🌟 ¡Hola! Soy Nadia, tu asistente conversacional.\n\n"
                "Puedes hablarme de forma natural o usar estos comandos:\n"
                "• /ayuda - Ver este mensaje\n"
                "• /estado - Ver mi estado actual\n"
                "• /version - Ver mi versión\n\n"
                "¡Cuéntame en qué puedo ayudarte! 💫"
            ),
            '/help': "Same as /ayuda 😊",
            '/estado': "✨ Estado: Funcionando perfectamente\n🧠 Memoria: Activa\n💬 Modo: Conversacional",
            '/status': "Same as /estado 🎯",
            '/version': "🤖 Nadia v0.2.0 - Sprint 2\n🧠 Arquitectura de Conciencia Adaptativa",
            '/start': "¡Hola! 👋 Soy Nadia. ¿En qué puedo ayudarte hoy?",
            '/stop': "¡Hasta pronto! 👋 Fue un placer conversar contigo.",
            '/comandos': "Usa /ayuda para ver todos los comandos disponibles 📋"
        }

        return fast_responses.get(message_lower, "Comando no reconocido. Usa /ayuda para ver los comandos disponibles.")

    async def _handle_message_direct(self, event):
        """Manejo directo de mensajes (fallback sin WAL)."""
        try:
            user_id = str(event.sender_id)
            message = event.text

            logger.warning(f"Procesando mensaje sin WAL de {user_id}: {message}")

            # Procesar mensaje con el supervisor
            response = await self.supervisor.process_message(user_id, message)

            # Enviar respuesta
            await event.reply(response)
            logger.info(f"Respuesta directa enviada: {response}")

        except Exception as e:
            logger.error(f"Error procesando mensaje directo: {e}")
            await event.reply(
                "Uf, perdona si tardo un poco... de repente siento que todo el mundo "
                "me está hablando a la vez y mi cabeza va a mil. Dame un segundito "
                "para poner mis ideas en orden. 😅"
            )


async def main():
    """Función principal."""
    config = Config.from_env()
    bot = UserBot(config)

    try:
        await bot.start()
    finally:
        await bot.cleanup()

if __name__ == "__main__":
    asyncio.run(main())


# ==== ./run_api.py ====

#!/usr/bin/env python3
# run_api.py
"""Script para ejecutar el servidor API de Nadia."""
import sys
from pathlib import Path

# Añadir el directorio raíz al path
sys.path.insert(0, str(Path(__file__).parent))

if __name__ == "__main__":
    import uvicorn

    from utils.config import Config

    config = Config.from_env()
    port = 8000  # Puerto por defecto

    print(f"🚀 Iniciando API Server de Nadia en puerto {port}")
    print(f"📍 Documentación disponible en: http://localhost:{port}/docs")
    print(f"🔐 Endpoint GDPR: DELETE http://localhost:{port}/users/{{user_id}}/memory")

    uvicorn.run(
        "api.server:app",
        host="0.0.0.0",
        port=port,
        reload=config.debug,
        log_level=config.log_level.lower()
    )


# ==== ./__init__.py ====



# ==== ./llms/openai_client.py ====

# llms/openai_client.py
"""Cliente wrapper para la API de OpenAI."""
import logging
from typing import Dict, List

from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class OpenAIClient:
    """Wrapper para interactuar con la API de OpenAI."""

    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        """Inicializa el cliente de OpenAI."""
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = model

    async def generate_response(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7
    ) -> str:
        """Genera una respuesta usando el modelo de OpenAI."""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=150
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"Error llamando a OpenAI: {e}")
            return "Lo siento, no pude procesar tu mensaje en este momento."


# ==== ./llms/__init__.py ====



# ==== ./memory/user_memory.py ====

# memory/user_memory.py
"""Gestor de memoria para almacenar contexto de usuarios."""
import json
import logging
from typing import Any, Dict

import redis.asyncio as redis

logger = logging.getLogger(__name__)


class UserMemoryManager:
    """Gestiona la memoria y contexto de cada usuario."""

    def __init__(self, redis_url: str):
        """Inicializa el gestor con conexión a Redis."""
        self.redis_url = redis_url
        self._redis = None

    async def _get_redis(self):
        """Obtiene o crea la conexión a Redis."""
        if not self._redis:
            self._redis = await redis.from_url(self.redis_url)
        return self._redis

    async def close(self):
        """Cierra la conexión a Redis limpiamente."""
        if self._redis:
            await self._redis.aclose()
            self._redis = None

    async def get_user_context(self, user_id: str) -> Dict[str, Any]:
        """Obtiene el contexto almacenado de un usuario."""
        try:
            r = await self._get_redis()
            data = await r.get(f"user:{user_id}")

            if data:
                return json.loads(data)
            return {}

        except Exception as e:
            logger.error(f"Error obteniendo contexto: {e}")
            return {}

    async def update_user_context(
        self,
        user_id: str,
        updates: Dict[str, Any]
    ) -> None:
        """Actualiza el contexto de un usuario."""
        try:
            r = await self._get_redis()

            # Obtener contexto actual
            context = await self.get_user_context(user_id)

            # Actualizar con nuevos datos
            context.update(updates)

            # Guardar
            await r.set(
                f"user:{user_id}",
                json.dumps(context),
                ex=86400 * 30  # Expirar en 30 días
            )

        except Exception as e:
            logger.error(f"Error actualizando contexto: {e}")

    async def set_name(self, user_id: str, name: str) -> None:
        """Almacena el nombre del usuario."""
        await self.update_user_context(user_id, {"name": name})
        logger.info(f"Nombre guardado para usuario {user_id}: {name}")

    async def delete_all_data_for_user(self, user_id: str) -> bool:
        """
        Elimina todos los datos de un usuario (GDPR - Derecho al olvido).

        Args:
            user_id: ID del usuario de Telegram

        Returns:
            True si se eliminó correctamente, False en caso de error
        """
        try:
            r = await self._get_redis()

            # Claves a eliminar para este usuario
            keys_to_delete = [
                f"user:{user_id}",  # Contexto principal
                f"user:{user_id}:*"  # Cualquier clave adicional futura
            ]

            # Buscar todas las claves relacionadas con el usuario
            deleted_count = 0
            for pattern in keys_to_delete:
                if '*' in pattern:
                    # Buscar claves con patrón
                    async for key in r.scan_iter(match=pattern):
                        await r.delete(key)
                        deleted_count += 1
                else:
                    # Eliminar clave directa
                    result = await r.delete(pattern)
                    deleted_count += result

            # También eliminar de cualquier cola de procesamiento
            # Eliminar mensajes pendientes del usuario en el WAL
            processing_key = f"nadia_processing:{user_id}"

            # Eliminar clave de procesamiento si existe
            await r.delete(processing_key)

            logger.info(f"Eliminadas {deleted_count} claves para usuario {user_id}")

            return True

        except Exception as e:
            logger.error(f"Error eliminando datos del usuario {user_id}: {e}")
            return False

    async def get_all_user_ids(self) -> list[str]:
        """
        Obtiene una lista de todos los IDs de usuarios almacenados.

        Returns:
            Lista de IDs de usuarios
        """
        try:
            r = await self._get_redis()
            user_ids = []

            # Buscar todas las claves de usuarios
            async for key in r.scan_iter(match="user:*"):
                # Extraer el user_id del formato "user:{user_id}"
                key_str = key.decode() if isinstance(key, bytes) else key
                if ':' in key_str and not key_str.count(':') > 1:
                    user_id = key_str.split(':')[1]
                    user_ids.append(user_id)

            return user_ids

        except Exception as e:
            logger.error(f"Error obteniendo lista de usuarios: {e}")
            return []


# ==== ./memory/__init__.py ====



# ==== ./agents/__init__.py ====



# ==== ./agents/supervisor_agent.py ====

# agents/supervisor_agent.py
"""Agente supervisor que orquesta la lógica de conversación."""
import logging
import re
from typing import Any, Dict

from llms.openai_client import OpenAIClient
from memory.user_memory import UserMemoryManager

logger = logging.getLogger(__name__)


class SupervisorAgent:
    """Orquestador principal de la lógica conversacional."""

    def __init__(self, llm_client: OpenAIClient, memory: UserMemoryManager):
        """Inicializa el supervisor con sus dependencias."""
        self.llm = llm_client
        self.memory = memory

    async def process_message(self, user_id: str, message: str) -> str:
        """Procesa un mensaje y genera una respuesta."""
        # Obtener contexto del usuario
        context = await self.memory.get_user_context(user_id)

        # Construir prompt
        prompt = self._build_prompt(message, context)

        # Generar respuesta
        response = await self.llm.generate_response(prompt)

        # Extraer información relevante (ej: nombre)
        await self._extract_and_store_info(user_id, message, response)

        return response

    def _build_prompt(self, message: str, context: Dict[str, Any]) -> list:
        """Construye el prompt para el LLM."""
        messages = [
            {
                "role": "system",
                "content": (
                    "Eres una asistente conversacional amigable y empática. "
                    "Tu objetivo es mantener conversaciones naturales y agradables. "
                    "Recuerda los detalles que los usuarios compartan contigo."
                )
            }
        ]

        # Añadir contexto si existe
        if context.get("name"):
            messages.append({
                "role": "system",
                "content": f"El usuario se llama {context['name']}."
            })

        # Añadir mensaje del usuario
        messages.append({
            "role": "user",
            "content": message
        })

        return messages

    async def _extract_and_store_info(self, user_id: str, message: str, response: str):
        """Extrae información del mensaje y la almacena."""
        # Buscar patrones de presentación
        name_patterns = [
            r"me llamo (\w+)",
            r"mi nombre es (\w+)",
            r"soy (\w+)",
            r"puedes llamarme (\w+)"
        ]

        for pattern in name_patterns:
            match = re.search(pattern, message.lower())
            if match:
                name = match.group(1).capitalize()
                await self.memory.set_name(user_id, name)
                logger.info(f"Nombre extraído y almacenado: {name}")
                break


# ==== ./tests/test_gdpr_api.py ====

# tests/test_gdpr_api.py
"""Tests para el endpoint GDPR de borrado de datos."""
import pytest
from fastapi.testclient import TestClient

from api.server import app
from memory.user_memory import UserMemoryManager
from utils.config import Config


class TestGDPRAPI:
    """Tests para verificar el cumplimiento GDPR."""

    @pytest.fixture
    def client(self):
        """Cliente de test para la API."""
        return TestClient(app)

    @pytest.fixture
    async def memory_manager(self):
        """Gestor de memoria para tests."""
        config = Config.from_env()
        return UserMemoryManager(config.redis_url)

    @pytest.mark.asyncio
    async def test_delete_existing_user(self, client, memory_manager):
        """Verifica el borrado exitoso de un usuario existente."""
        user_id = "test_user_123"

        # Crear datos de usuario
        await memory_manager.update_user_context(
            user_id,
            {"name": "Test User", "age": 25}
        )

        # Verificar que el usuario existe
        context = await memory_manager.get_user_context(user_id)
        assert context["name"] == "Test User"

        # Llamar al endpoint de borrado
        response = client.delete(f"/users/{user_id}/memory")
        assert response.status_code == 204

        # Verificar que los datos fueron eliminados
        context = await memory_manager.get_user_context(user_id)
        assert context == {}

    def test_delete_nonexistent_user(self, client):
        """Verifica el manejo de usuarios no existentes."""
        response = client.delete("/users/nonexistent_user/memory")
        assert response.status_code == 404
        assert "no encontrado" in response.json()["detail"]

    def test_health_endpoint(self, client):
        """Verifica el endpoint de salud."""
        response = client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] in ["healthy", "unhealthy"]
        assert "services" in response.json()

    def test_root_endpoint(self, client):
        """Verifica el endpoint raíz."""
        response = client.get("/")
        assert response.status_code == 200
        assert "Nadia Bot API" in response.json()["message"]
        assert "endpoints" in response.json()

    @pytest.mark.asyncio
    async def test_get_user_memory(self, client, memory_manager):
        """Verifica la lectura de memoria de usuario."""
        user_id = "test_read_user"
        test_data = {"name": "Reader", "preferences": ["chat", "music"]}

        # Crear datos
        await memory_manager.update_user_context(user_id, test_data)

        # Leer mediante API
        response = client.get(f"/users/{user_id}/memory")
        assert response.status_code == 200

        data = response.json()
        assert data["user_id"] == user_id
        assert data["context"]["name"] == "Reader"
        assert "preferences" in data["context"]

    def test_get_nonexistent_user_memory(self, client):
        """Verifica el manejo de lectura de usuarios no existentes."""
        response = client.get("/users/ghost_user/memory")
        assert response.status_code == 404

    @pytest.mark.asyncio
    async def test_delete_user_with_multiple_keys(self, client, memory_manager):
        """Verifica el borrado completo de usuarios con múltiples claves."""
        user_id = "complex_user"

        # Crear múltiples entradas para el usuario
        await memory_manager.update_user_context(
            user_id,
            {"name": "Complex", "data": "main"}
        )

        # Simular claves adicionales (para futuras extensiones)
        r = await memory_manager._get_redis()
        await r.set(f"user:{user_id}:preferences", '{"theme": "dark"}')
        await r.set(f"user:{user_id}:history", '[]')

        # Verificar que existen múltiples claves
        keys = []
        async for key in r.scan_iter(match=f"user:{user_id}*"):
            keys.append(key)
        assert len(keys) >= 1  # Al menos la clave principal

        # Borrar mediante API
        response = client.delete(f"/users/{user_id}/memory")
        assert response.status_code == 204

        # Verificar que todas las claves fueron eliminadas
        keys_after = []
        async for key in r.scan_iter(match=f"user:{user_id}*"):
            keys_after.append(key)
        assert len(keys_after) == 0


# ==== ./tests/test_wal_integration.py ====

# tests/test_wal_integration.py
"""Tests de integración para el Write-Ahead Log."""
import asyncio
import json

import pytest
import redis.asyncio as redis

from utils.config import Config


@pytest.mark.asyncio
class TestWALIntegration:
    """Tests para verificar la robustez del WAL."""

    @pytest.fixture
    async def redis_client(self, redis_cleanup):
        """Cliente Redis para tests."""
        config = Config.from_env()
        r = await redis.from_url(config.redis_url)
        yield r
        # Limpiar después del test
        await r.flushdb()
        await r.aclose()

    async def test_message_enqueue(self, redis_client):
        """Verifica que los mensajes se encolen correctamente."""
        queue_key = "nadia_message_queue"

        # Simular encolado de mensaje
        message_data = {
            'user_id': '12345',
            'message': 'Hola test',
            'chat_id': -1001234567890,
            'message_id': 42,
            'timestamp': '2024-01-01T12:00:00'
        }

        await redis_client.lpush(queue_key, json.dumps(message_data))

        # Verificar que el mensaje está en la cola
        queue_length = await redis_client.llen(queue_key)
        assert queue_length == 1

        # Recuperar y verificar el mensaje
        result = await redis_client.brpop(queue_key, timeout=1)
        assert result is not None

        _, message_json = result
        recovered_data = json.loads(message_json)
        assert recovered_data == message_data

    async def test_multiple_messages_order(self, redis_client):
        """Verifica que múltiples mensajes mantengan el orden FIFO."""
        queue_key = "nadia_message_queue"

        # Encolar varios mensajes
        messages = []
        for i in range(5):
            msg = {
                'user_id': f'user_{i}',
                'message': f'Mensaje {i}',
                'chat_id': -1001234567890,
                'message_id': i,
                'timestamp': f'2024-01-01T12:00:0{i}'
            }
            messages.append(msg)
            await redis_client.lpush(queue_key, json.dumps(msg))

        # Verificar que se recuperan en orden FIFO
        for i in range(5):
            result = await redis_client.brpop(queue_key, timeout=1)
            assert result is not None

            _, message_json = result
            recovered_data = json.loads(message_json)
            assert recovered_data['message'] == f'Mensaje {i}'

    async def test_processing_marker(self, redis_client):
        """Verifica el marcador de procesamiento."""
        processing_key = "nadia_processing:user123"

        # Marcar como en procesamiento
        message_data = {'user_id': 'user123', 'message': 'Test'}
        await redis_client.set(
            processing_key,
            json.dumps(message_data),
            ex=300  # 5 minutos
        )

        # Verificar que existe
        exists = await redis_client.exists(processing_key)
        assert exists == 1

        # Verificar TTL
        ttl = await redis_client.ttl(processing_key)
        assert 290 < ttl <= 300  # Aproximadamente 5 minutos

        # Limpiar
        await redis_client.delete(processing_key)
        exists = await redis_client.exists(processing_key)
        assert exists == 0

    async def test_concurrent_processing(self, redis_client):
        """Simula procesamiento concurrente de mensajes."""
        queue_key = "nadia_message_queue"
        processed_messages = []

        async def process_worker(worker_id: int):
            """Worker que procesa mensajes."""
            while True:
                result = await redis_client.brpop(queue_key, timeout=1)
                if result is None:
                    break

                _, message_json = result
                data = json.loads(message_json)
                processed_messages.append({
                    'worker_id': worker_id,
                    'message': data['message']
                })
                await asyncio.sleep(0.1)  # Simular procesamiento

        # Encolar mensajes
        for i in range(10):
            msg = {'message': f'Msg-{i}', 'user_id': f'user_{i}'}
            await redis_client.lpush(queue_key, json.dumps(msg))

        # Iniciar workers concurrentes
        workers = [
            asyncio.create_task(process_worker(i))
            for i in range(3)
        ]

        # Esperar a que terminen
        await asyncio.gather(*workers)

        # Verificar que todos los mensajes fueron procesados
        assert len(processed_messages) == 10

        # Verificar que no hay mensajes duplicados
        processed_texts = [m['message'] for m in processed_messages]
        assert len(set(processed_texts)) == 10


# ==== ./tests/test_greet.py ====

# tests/test_greet.py
"""Tests básicos para el flujo de saludo."""
import pytest


@pytest.mark.asyncio
async def test_greeting_extracts_name(supervisor, mock_memory):
    """Verifica que se extraiga y almacene el nombre del saludo."""
    # Simular mensaje de saludo
    user_id = "123"
    message = "Hola, me llamo Ana"

    # Procesar mensaje
    response = await supervisor.process_message(user_id, message)

    # Verificar que se guardó el nombre
    mock_memory.set_name.assert_called_once_with(user_id, "Ana")
    assert "Ana" in response


@pytest.mark.asyncio
async def test_greeting_remembers_name(supervisor, mock_memory):
    """Verifica que se recuerde el nombre en conversaciones posteriores."""
    # Configurar contexto con nombre
    mock_memory.get_user_context.return_value = {"name": "Carlos"}

    # Procesar mensaje
    user_id = "456"
    message = "¿Cómo estás?"

    response = await supervisor.process_message(user_id, message)
    assert "Ana" in response
    # Verificar que se usó el contexto
    mock_memory.get_user_context.assert_called_once_with(user_id)
    # El LLM debería haber recibido el nombre en el prompt
    call_args = supervisor.llm.generate_response.call_args[0][0]
    assert any("Carlos" in msg["content"] for msg in call_args)


# ==== ./tests/test_redis_connection.py ====

# test_redis_connection.py
import asyncio

import redis.asyncio as redis


async def test_redis():
    """Prueba la conexión a Redis."""
    try:
        # Conectar
        r = await redis.from_url("redis://localhost:6379/0")

        # Probar operaciones básicas
        await r.set("test_key", "¡Funciona!")
        value = await r.get("test_key")
        print(f"Valor recuperado: {value.decode()}")

        # Limpiar
        await r.delete("test_key")

        # Cerrar conexión
        await r.aclose()

        print("✅ Redis funciona correctamente")

    except Exception as e:
        print(f"❌ Error conectando a Redis: {e}")
        print("Verifica que Redis esté corriendo: sudo systemctl status redis-server")


if __name__ == "__main__":
    asyncio.run(test_redis())


# ==== ./tests/__init__.py ====



# ==== ./tests/conftest.py ====

# conftest.py
"""Configuración global de pytest para el proyecto."""
import asyncio
import sys
from pathlib import Path

import pytest
import redis.asyncio as redis

# Agregar el directorio raíz al path
sys.path.insert(0, str(Path(__file__).parent))

@pytest.fixture
async def redis_cleanup():
    """
    Fixture que garantiza la limpieza de conexiones Redis.

    Este fixture se ejecuta después de cada test que lo use,
    cerrando todas las conexiones Redis pendientes.
    """
    # Setup (antes del test)
    connections = []

    # Guardar referencia a la función original
    original_from_url = redis.from_url

    async def wrapped_from_url(*args, **kwargs):
        """Wrapper que rastrea conexiones creadas."""
        conn = await original_from_url(*args, **kwargs)
        connections.append(conn)
        return conn

    # Reemplazar temporalmente
    redis.from_url = wrapped_from_url

    yield

    # Teardown (después del test)
    # Restaurar función original
    redis.from_url = original_from_url

    # Cerrar todas las conexiones rastreadas
    for conn in connections:
        try:
            await conn.aclose()
        except Exception:
            pass  # Ignorar errores al cerrar
@pytest.fixture(scope="session")
def event_loop():
    """
    Crea un event loop para toda la sesión de tests.

    Esto ayuda a evitar problemas de "Event loop is closed"
    al reutilizar el mismo loop.
    """
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()

    yield loop

    # Dar tiempo para que se completen las tareas pendientes
    pending = asyncio.all_tasks(loop)
    if pending:
        loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

    # Cerrar el loop limpiamente
    loop.close()
# Marcar todos los tests como asyncio por defecto
def pytest_collection_modifyitems(items):
    """Marca automáticamente los tests async con pytest.mark.asyncio."""
    pytest_asyncio_mark = pytest.mark.asyncio
    for item in items:
        if asyncio.iscoroutinefunction(item.obj):
            item.add_marker(pytest_asyncio_mark)


# ==== ./tests/test_cognitive_controller.py ====

# tests/test_cognitive_controller.py
"""Tests para el Controlador Cognitivo."""
import pytest

from cognition.cognitive_controller import CognitiveController


class TestCognitiveController:
    """Tests para la lógica de enrutamiento del controlador."""

    @pytest.fixture
    def controller(self):
        """Crea una instancia del controlador para tests."""
        return CognitiveController()

    def test_fast_path_commands(self, controller):
        """Verifica que los comandos se enruten a fast_path."""
        fast_commands = [
            "/ayuda",
            "/AYUDA",  # Mayúsculas
            "/help",
            "/start",
            "/stop",
            "/estado",
            "/status",
            "/version",
            "/comandos"
        ]

        for command in fast_commands:
            route = controller.route_message(command)
            assert route == 'fast_path', f"Comando {command} debería ir por fast_path"

    def test_slow_path_conversations(self, controller):
        """Verifica que las conversaciones normales vayan por slow_path."""
        conversations = [
            "Hola, ¿cómo estás?",
            "Me llamo Juan",
            "¿Qué puedes hacer?",
            "Cuéntame un chiste",
            "¿Cuál es el sentido de la vida?",
            "/comando_inexistente",
            "ayuda",  # Sin slash
            ""  # Mensaje vacío
        ]

        for message in conversations:
            route = controller.route_message(message)
            assert route == 'slow_path', f"Mensaje '{message}' debería ir por slow_path"

    def test_whitespace_handling(self, controller):
        """Verifica el manejo correcto de espacios en blanco."""
        # Comandos con espacios
        assert controller.route_message("  /ayuda  ") == 'fast_path'
        assert controller.route_message("/ayuda ") == 'fast_path'
        assert controller.route_message(" /ayuda") == 'fast_path'

        # Comandos con texto adicional van por slow_path
        assert controller.route_message("/ayuda algo más") == 'slow_path'
        assert controller.route_message("/help me please") == 'slow_path'

    def test_add_custom_pattern(self, controller):
        """Verifica que se puedan añadir nuevos patrones."""
        # Añadir patrón personalizado
        controller.add_fast_path_pattern(r'^/custom$')

        # Verificar que funciona
        assert controller.route_message("/custom") == 'fast_path'
        assert controller.route_message("/custom extra") == 'slow_path'

    def test_case_insensitive(self, controller):
        """Verifica que los comandos sean case-insensitive."""
        variations = ["/AYUDA", "/Ayuda", "/aYuDa", "/ayuda"]

        for variant in variations:
            assert controller.route_message(variant) == 'fast_path'


# ==== ./api/server.py ====

# api/server.py
"""Servidor API para gestión del bot y cumplimiento GDPR."""
import logging

import redis.asyncio as redis
from fastapi import FastAPI, HTTPException, Response
from fastapi.middleware.cors import CORSMiddleware

from memory.user_memory import UserMemoryManager
from utils.config import Config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Crear app FastAPI
app = FastAPI(
    title="Nadia Bot API",
    description="API para gestión del bot Nadia y cumplimiento GDPR",
    version="0.2.0"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producción, especificar dominios permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuración global
config = Config.from_env()
memory_manager = UserMemoryManager(config.redis_url)


@app.on_event("startup")
async def startup_event():
    """Inicialización al arrancar el servidor."""
    logger.info("API Server iniciando...")


@app.on_event("shutdown")
async def shutdown_event():
    """Limpieza al cerrar el servidor."""
    logger.info("API Server cerrando...")
    await memory_manager.close()


@app.get("/")
async def root():
    """Endpoint raíz de bienvenida."""
    return {
        "message": "Nadia Bot API",
        "version": "0.2.0",
        "endpoints": {
            "health": "/health",
            "delete_user": "DELETE /users/{user_id}/memory"
        }
    }


@app.get("/health")
async def health_check():
    """Verifica el estado de salud del servicio."""
    try:
        # Verificar conexión a Redis
        r = await redis.from_url(config.redis_url)
        await r.ping()
        await r.aclose()

        return {
            "status": "healthy",
            "services": {
                "api": "ok",
                "redis": "ok"
            }
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "unhealthy",
            "services": {
                "api": "ok",
                "redis": "error"
            },
            "error": str(e)
        }


@app.delete("/users/{user_id}/memory", status_code=204)
async def delete_user_data(user_id: str):
    """
    Elimina todos los datos de un usuario (GDPR - Derecho al olvido).

    Args:
        user_id: ID del usuario de Telegram

    Returns:
        204 No Content si se eliminó correctamente
        404 Not Found si el usuario no existe
        500 Internal Server Error si hay un error
    """
    try:
        logger.info(f"Solicitud de borrado GDPR para usuario {user_id}")

        # Verificar si el usuario existe
        context = await memory_manager.get_user_context(user_id)
        if not context:
            raise HTTPException(
                status_code=404,
                detail=f"Usuario {user_id} no encontrado"
            )

        # Eliminar todos los datos del usuario
        deleted = await memory_manager.delete_all_data_for_user(user_id)

        if deleted:
            logger.info(f"Datos del usuario {user_id} eliminados exitosamente")
            return Response(status_code=204)
        else:
            raise HTTPException(
                status_code=500,
                detail="Error al eliminar los datos del usuario"
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error eliminando datos del usuario {user_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail="Error interno del servidor"
        )


@app.get("/users/{user_id}/memory")
async def get_user_memory(user_id: str):
    """
    Obtiene el contexto/memoria de un usuario (para verificación).

    Args:
        user_id: ID del usuario de Telegram

    Returns:
        El contexto almacenado del usuario
    """
    try:
        context = await memory_manager.get_user_context(user_id)
        if not context:
            raise HTTPException(
                status_code=404,
                detail=f"Usuario {user_id} no encontrado"
            )

        return {
            "user_id": user_id,
            "context": context
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error obteniendo memoria del usuario {user_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail="Error interno del servidor"
        )


if __name__ == "__main__":
    import uvicorn

    # Configurar puerto desde variables de entorno o usar 8000
    port = int(config.api_port) if hasattr(config, 'api_port') else 8000

    uvicorn.run(
        "api.server:app",
        host="0.0.0.0",
        port=port,
        reload=config.debug,
        log_level=config.log_level.lower()
    )


# ==== ./api/__init__.py ====



# ==== ./utils/validators.py ====



# ==== ./utils/config.py ====

# utils/config.py
"""Configuración centralizada del proyecto."""
import os
from dataclasses import dataclass

from dotenv import load_dotenv

load_dotenv()


@dataclass
class Config:
    """Configuración de la aplicación."""
    # Telegram
    api_id: int
    api_hash: str
    phone_number: str
    openai_api_key: str
    redis_url: str

    # opcionales / con default
    openai_model: str = "gpt-3.5-turbo"
    debug: bool = False
    log_level: str = "INFO"

    # App
    api_port: int = 8000

    @classmethod
    def from_env(cls) -> "Config":
        """Crea configuración desde variables de entorno."""
        return cls(
            api_id=int(os.getenv("API_ID", "0")),
            api_hash=os.getenv("API_HASH", ""),
            phone_number=os.getenv("PHONE_NUMBER", ""),
            openai_api_key=os.getenv("OPENAI_API_KEY", ""),
            redis_url=os.getenv("REDIS_URL", "redis://localhost:6379/0"),
            debug=os.getenv("DEBUG", "False").lower() == "true",
            log_level=os.getenv("LOG_LEVEL", "INFO"),
            api_port=int(os.getenv("API_PORT", "8000"))
        )




# ==== ./utils/__init__.py ====



# ==== ./cognition/cognitive_controller.py ====

# cognition/cognitive_controller.py
"""Controlador cognitivo que actúa como router entre vías de procesamiento."""
import logging
import re
from typing import Literal

logger = logging.getLogger(__name__)


class CognitiveController:
    """
    Controlador que decide si un mensaje debe ir por la vía rápida o lenta.

    El Controlador Cognitivo actúa como el "neocórtex" del sistema, tomando
    decisiones rápidas sobre cómo procesar cada mensaje entrante.
    """

    def __init__(self):
        """Inicializa el controlador con patrones de comandos rápidos."""
        # Patrones de comandos que siempre van por vía rápida
        self.fast_path_patterns = [
            r'^/ayuda$',
            r'^/help$',
            r'^/start$',
            r'^/stop$',
            r'^/estado$',
            r'^/status$',
            r'^/version$',
            r'^/comandos$',
        ]

        # Compilar regex para mejor rendimiento
        self.compiled_patterns = [
            re.compile(pattern, re.IGNORECASE)
            for pattern in self.fast_path_patterns
        ]

        logger.info("CognitiveController inicializado con patrones de vía rápida")

    def route_message(self, message: str) -> Literal['fast_path', 'slow_path']:
        """
        Determina la ruta de procesamiento para un mensaje.

        Args:
            message: El mensaje del usuario a analizar

        Returns:
            'fast_path' para comandos simples
            'slow_path' para conversaciones complejas
        """
        # Sanitizar mensaje
        message = message.strip()

        # Verificar si es un comando de vía rápida
        for pattern in self.compiled_patterns:
            if pattern.match(message):
                logger.info(f"Mensaje '{message}' enrutado a fast_path")
                return 'fast_path'

        # TODO: En el futuro, aquí irá la lógica de embeddings para:
        # - Detectar preguntas frecuentes
        # - Analizar complejidad semántica
        # - Evaluar carga emocional
        # - Determinar necesidad de contexto histórico

        # Por ahora, todo lo demás va por vía lenta (personalizada)
        logger.info(f"Mensaje '{message[:50]}...' enrutado a slow_path")
        return 'slow_path'

    def add_fast_path_pattern(self, pattern: str):
        """
        Añade un nuevo patrón a la lista de vía rápida.

        Args:
            pattern: Expresión regular para comandos rápidos
        """
        self.fast_path_patterns.append(pattern)
        self.compiled_patterns.append(re.compile(pattern, re.IGNORECASE))
        logger.info(f"Nuevo patrón añadido a fast_path: {pattern}")


# ==== ./cognition/__init__.py ====

"""Módulo de cognición - Sistema de control y decisión del bot."""


